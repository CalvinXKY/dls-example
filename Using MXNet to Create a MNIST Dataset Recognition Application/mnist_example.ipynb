{"nbformat_minor": 2, "cells": [{"source": "# \u4f7f\u7528MoXing\u5b9e\u73b0\u624b\u5199\u6570\u5b57\u56fe\u50cf\u8bc6\u522b\u5e94\u7528", "cell_type": "markdown", "metadata": {}}, {"source": "  &#160;&#160;\u672c\u5185\u5bb9\u4e3b\u8981\u4ecb\u7ecd\uff0c\u5982\u4f55\u4f7f\u7528MoXing\u5b9e\u73b0\u624b\u5199\u6570\u5b57\u56fe\u50cf\u7684\u8bad\u7ec3\u3001\u6d4b\u8bd5\u5e94\u7528\u3002\n\n### 1. \u51c6\u5907\u6570\u636e\n\n  &#160;&#160;\u4e0b\u8f7dMNIST\u6570\u636e\u96c6\uff0c\u89e3\u538b\u7f29\u4e4b\u540e\u4e0a\u4f20\u81f3OBS\u6876\u4e2d\u3002\u5177\u4f53\u64cd\u4f5c\u5982\u4e0b\uff1a\n**\u6b65\u9aa4 1**  &#160; &#160; \u4e0b\u8f7dMNIST\u6570\u636e\u96c6\uff0c \u6570\u636e\u96c6\u6587\u4ef6\u8bf4\u660e\u5982\u4e0b\uff1a\n- t10k-images-idx3-ubyte.gz\uff1a\u9a8c\u8bc1\u96c6\uff0c\u5171\u5305\u542b10000\u4e2a\u6837\u672c\u3002<a href = \"https://dls-obs.obs.cn-north-1.myhwclouds.com/mnist_example/mnist_data/t10k-images-idx3-ubyte.gz\">\u4e0b\u8f7d\u6570\u636e</a>\n- t10k-labels-idx1-ubyte.gz\uff1a\u9a8c\u8bc1\u96c6\u6807\u7b7e\uff0c\u5171\u5305\u542b10000\u4e2a\u6837\u672c\u7684\u7c7b\u522b\u6807\u7b7e\u3002<a href = \"https://dls-obs.obs.cn-north-1.myhwclouds.com/mnist_example/mnist_data/t10k-labels-idx1-ubyte.gz\">\u4e0b\u8f7d\u6570\u636e</a>\n- train-images-idx3-ubyte.gz\uff1a\u8bad\u7ec3\u96c6\uff0c\u5171\u5305\u542b60000\u4e2a\u6837\u672c\u3002<a href = \"https://dls-obs.obs.cn-north-1.myhwclouds.com/mnist_example/mnist_data/train-images-idx3-ubyte.gz\">\u4e0b\u8f7d\u6570\u636e</a>\n- train-labels-idx1-ubyte.gz\uff1a\u8bad\u7ec3\u96c6\u6807\u7b7e\uff0c\u5171\u5305\u542b60000\u4e2a\u6837\u672c\u7684\u7c7b\u522b\u6807\u7b7e\u3002<a href = \"https://dls-obs.obs.cn-north-1.myhwclouds.com/mnist_example/mnist_data/train-labels-idx1-ubyte.gz\">\u4e0b\u8f7d\u6570\u636e</a>\n.gz\u6570\u636e\u65e0\u9700\u89e3\u538b\uff0c\u53c2\u8003<a href = \"https://support.huaweicloud.com/usermanual-dls/dls_01_0040.html\">\u201c\u4e0a\u4f20\u4e1a\u52a1\u6570\u636e\u201d</a>\u7ae0\u8282\u5185\u5bb9\uff0c\u5206\u522b\u4e0a\u4f20\u81f3\u534e\u4e3a\u4e91OBS\u6876 \uff08\u5047\u8bbeOBS\u6876\u8def\u5f84\u4e3a\uff1as3://zzy/zzy/data/mnist/\uff09\u3002", "cell_type": "markdown", "metadata": {}}, {"source": "### 2. \u8bad\u7ec3\u6a21\u578b\n\n  &#160;&#160;\u901a\u8fc7import\u52a0\u8f7dmoxing\u7684tensorflow\u6a21\u5757 moxing.tensorflow ", "cell_type": "markdown", "metadata": {}}, {"source": "from tensorflow.examples.tutorials.mnist import input_data\nimport tensorflow as tf\nimport moxing.tensorflow as mox\nimport os\nfrom __future__ import print_function\nfrom __future__ import unicode_literals", "cell_type": "code", "execution_count": 1, "outputs": [], "metadata": {}}, {"source": "**\u8bf4\u660e 1**  &#160; &#160; \u51fd\u6570 tf.flags.DEFINE_string('data_url', 's3://zzy/zzy/data/mnist', 'Dir of dataset')\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e3a\u6570\u636e\u8def\u5f84\u3002\n                  \u51fd\u6570tf.flags.DEFINE_string('train_url', 's3://obs-dls-mnist-example/log/ ', 'Train Url') \u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e3a\u65e5\u5fd7\u4ee5\u53ca\u751f\u4ea7\u6a21\u578b\u7684\u5b58\u50a8\u8def\u5f84\u3002", "cell_type": "markdown", "metadata": {}}, {"source": "tf.flags.DEFINE_string('data_url', 's3://zzy/zzy/data/mnist', 'Dir of dataset')\ntf.flags.DEFINE_string('train_url', 's3://obs-dls-mnist-example/log/', 'Train Url')\n\nflags = tf.flags.FLAGS\n\nwork_directory = flags.data_url\nfilenames = ['train-images-idx3-ubyte.gz','train-labels-idx1-ubyte.gz','t10k-images-idx3-ubyte.gz',\n             't10k-labels-idx1-ubyte.gz']\n\nfor filename in filenames:\n  filepath = os.path.join(work_directory, filename)\n  if not mox.file.exists(filepath):\n    raise ValueError('MNIST dataset file %s not found in %s' % (filepath, work_directory))", "cell_type": "code", "execution_count": 2, "outputs": [], "metadata": {}}, {"source": "  &#160;&#160;\u8bad\u7ec3\u7684main\u51fd\u6570\u5305\u542b\u4e09\u4e2a\u90e8\u5206\uff0c\u8f93\u5165\u5b9a\u4e49\u3001\u6a21\u578b\u5b9a\u4e49\u548c\u8fd0\u884c\u3002\n\n1\uff09 \u8f93\u5165\u51fd\u6570\uff1ainput_fn(run_mode, **kwargs) \u7528\u6237\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u8f93\u5165\u7f16\u5199\u3002\u672c\u4f8b\u4e2d\u901a\u8fc7\u8fed\u4ee3\u7684\u65b9\u5f0f\u4ece\u6570\u636e\u96c6\u4e2d\u53d6\u6570\u636e\u3002\n\n\n2\uff09 \u6a21\u578b\u5b9a\u4e49\uff1adef model_fn(inputs, run_mode, **kwargs): \u6a21\u578b\u7ed3\u6784\u5b9a\u4e49\u51fd\u6570\uff0c\u8fd4\u56de mox.ModelSpec(\uff09\uff0c\u7528\u6237\u4f5c\u4e1a\u6a21\u5f0f\u5b9a\u4e49\u8fd4\u56de\u503c\u3002\n\u4f46\u9700\u8981\u6ee1\u8db3\u5982\u4e0b\u6761\u4ef6\uff1a\n\n &#160;&#160; For run_mode == ModeKeys.TRAIN: `loss` is required.\n  \n  &#160;&#160;  For run_mode == ModeKeys.EVAL: `log_info` is required.\n  \n  &#160;&#160;  For run_mode == ModeKeys.PREDICT: `output_info` is required.\n  \n  &#160;&#160;  For run_mode == ModeKeys.EXPORT: `export_spec` is required.\n  \n\n3\uff09 \u6267\u884c\u8bad\u7ec3\uff1a mox.run(\uff09\uff0c\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u53ef\u6307\u5b9aoptimizer\u7684\u4e00\u4e9b\u8bbe\u7f6e\uff0c\u8bad\u7ec3batch\u7684\u5927\u5c0f\u7b49\uff0c\u8bbe\u7f6e\u5185\u5bb9\u5982\u4e0b\uff1a\n\n\n &#160;&#160; \u8f93\u5165\u51fd\u6570\uff0c input_fn: An input_fn defined by user. Allows tfrecord or python data. Returns  input tensor list.\n \n &#160;&#160;  \u6a21\u578b\u51fd\u6570\uff0c model_fn: A model_fn defined by user. Returns `mox.ModelSpec`.\n  \n  &#160;&#160; optimizer\u5b9a\u4e49\uff0c optimizer_fn: An optimizer_fn defined by user. Returns an optimizer.\n  \n  &#160;&#160; \u8fd0\u884c\u6a21\u5f0f\u9009\u62e9\uff0c run_mode: Only takes mox.ModeKeys.TRAIN or mox.ModeKeys.EVAL or mox.ModeKeys.PREDICT\n  \n  &#160;&#160; batch\u5927\u5c0f\u8bbe\u7f6e\uff0c batch_size: Mini-batch size.\n  \n &#160;&#160;  \u662f\u5426\u81ea\u52a8\u5316batch\uff0c auto_batch: If True, an extra dimension of batch_size will be expanded to the first\n                     dimension of the return value from `get_split`. Default to True.\n                     \n  &#160;&#160; \u65e5\u5fd7\u4ee5\u53cacheckpoint\u4fdd\u5b58\u4f4d\u7f6e\uff0c log_dir: The directory to save summaries and checkpoints.\n  \n  &#160;&#160; \u6700\u5927\u6570\u91cf\uff0c  max_number_of_steps: Maximum steps for each worker.\n                          \n  &#160;&#160; \u65e5\u5fd7\u6253\u5370\uff0c log_every_n_steps: Step period to print logs to std I/O.\n     \n  &#160;&#160; \u662f\u5426\u8f93\u51fa\u6a21\u578b\uff0c export_model: True or False. Where to export model after running the job.\n\n", "cell_type": "markdown", "metadata": {}}, {"source": "def main(*args):\n  mnist = input_data.read_data_sets(flags.data_url, one_hot=True)\n\n\n  # define the input dataset, return image and label\n  def input_fn(run_mode, **kwargs):\n    def gen():\n      while True:\n        yield mnist.train.next_batch(50)\n    ds = tf.data.Dataset.from_generator(\n        gen, output_types=(tf.float32, tf.int64),\n        output_shapes=(tf.TensorShape([None, 784]), tf.TensorShape([None, 10])))\n    return ds.make_one_shot_iterator().get_next()\n\n\n  # define the model for training or evaling.\n  def model_fn(inputs, run_mode, **kwargs):\n    x, y_ = inputs\n    W = tf.get_variable(name='W', initializer=tf.zeros([784, 10]))\n    b = tf.get_variable(name='b', initializer=tf.zeros([10]))\n    y = tf.matmul(x, W) + b\n    cross_entropy = tf.reduce_mean(\n      tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n    predictions = tf.argmax(y, 1)\n    correct_predictions = tf.equal(predictions, tf.argmax(y_, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n    export_spec = mox.ExportSpec(inputs_dict={'images': x}, outputs_dict={'predictions': predictions}, version='model')\n    return mox.ModelSpec(loss=cross_entropy, log_info={'loss': cross_entropy, 'accuracy': accuracy},\n                         export_spec=export_spec)\n\n\n  mox.run(input_fn=input_fn,\n          model_fn=model_fn,\n          optimizer_fn=mox.get_optimizer_fn('sgd', learning_rate=0.01),\n          run_mode=mox.ModeKeys.TRAIN,\n          batch_size=50,\n          auto_batch=False,\n          log_dir=flags.train_url,\n          max_number_of_steps=1000,\n          log_every_n_steps=10,\n          export_model=mox.ExportKeys.TF_SERVING)\n\nif __name__ == '__main__':\n  tf.app.run(main=main)", "cell_type": "code", "execution_count": 3, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Extracting s3://zzy/zzy/data/mnist/train-images-idx3-ubyte.gz\nExtracting s3://zzy/zzy/data/mnist/train-labels-idx1-ubyte.gz\nExtracting s3://zzy/zzy/data/mnist/t10k-images-idx3-ubyte.gz\nExtracting s3://zzy/zzy/data/mnist/t10k-labels-idx1-ubyte.gz\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Restoring parameters from s3://obs-dls-mnist-example/log/model.ckpt-1000\nINFO:tensorflow:Running will end at step: 1000\nINFO:tensorflow:Saving checkpoints for 1000 into s3://obs-dls-mnist-example/log/model.ckpt.\nINFO:tensorflow:No assets to save.\nINFO:tensorflow:No assets to write.\nINFO:tensorflow:Restoring parameters from s3://obs-dls-mnist-example/log/model.ckpt-1000\nINFO:tensorflow:SavedModel written to: s3://obs-dls-mnist-example/log/model/saved_model.pb\n"}, {"output_type": "error", "evalue": "", "traceback": ["An exception has occurred, use %tb to see the full traceback.\n", "\u001b[0;31mSystemExit\u001b[0m\n"], "ename": "SystemExit"}, {"output_type": "stream", "name": "stderr", "text": "/home/work/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"}], "metadata": {}}, {"source": "### 3. \u9884\u6d4b\n\n", "cell_type": "markdown", "metadata": {}}, {"source": "   &#160;&#160;\u5728\u4e0a\u9762\u8bad\u7ec3\u7684\u57fa\u7840\u4e0a\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u7528\u8bad\u7ec3\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u4f5c\u4e1a\u3002\u5982\u8bfb\u53d6OBS\u6876\u4e2d\u7684\u6570\u5b57\u56fe\u7247\u8fdb\u884c\u8bc6\u522b\uff08\u5047\u8bbe\u4f4d\u7f6e\uff1a's3://obs-dls-mnist-example/7.jpg'\uff09\u3002input_fn \u5bf9\u8f93\u5165\u56fe\u7247\u8fdb\u884c\u7b80\u5355\u5904\u7406\uff0c\u5f97\u5230\u7f51\u7edc\u5141\u8bb8\u7684\u8f93\u5165tensor\uff1bmodel_fn\u5b9a\u4e49\u4e00\u4e2a\u9884\u6d4b\u5185\u5bb9\uff0c\u540c\u65f6\uff0c\u8fd8\u9700\u5b9a\u4e49\u4e00\u4e2a\u5bf9\u8f93\u51fa\u5904\u7406\u7684\u51fd\u6570output_fn\uff0c\u6211\u4eec\u5728\u6539\u51fd\u6570\u91cc\u5bf9\u8f93\u51fa\u8fdb\u884c\u4e00\u4e2a\u6253\u5370\u8f93\u51fa\u3002\n \n  \u8fd8\u9700\u5728 mox.run()\u51fd\u6570\u4e2d\u52a0\u5165\u5982\u4e0b\u53c2\u6570\uff1a\n  \n  &#160;&#160;   \u8f93\u51fa\u51fd\u6570 output_fn: A callback with args of results from sess.run.\n   \n  &#160;&#160; \u6a21\u578b\u52a0\u8f7d\u4f4d\u7f6e checkpoint_path: Directory or file path of ckpt to restore when `run_mode` is 'evaluation'.\n                          Useless when `run_mode` is 'train'.", "cell_type": "markdown", "metadata": {}}, {"source": "def predict(*args):\n  def input_fn(run_mode, **kwargs):\n    image = tf.read_file('s3://obs-dls-mnist-example/7.jpg')\n    img = tf.image.decode_jpeg(image, channels=1)\n    img = tf.image.resize_images(img, [28, 28], 0)\n    img = tf.reshape(img, [784])\n    return img\n\n  def model_fn(inputs, run_mode, **kwargs):\n    x = inputs\n    W1 = tf.get_variable(name='W', initializer=tf.zeros([784, 10]))\n    b1 = tf.get_variable(name='b', initializer=tf.zeros([10]))\n    y = tf.matmul(x, W1) + b1\n    predictions = tf.argmax(y, 1)\n    return mox.ModelSpec(output_info={'predict': predictions})\n\n  def output_fn(outputs):\n    for output in outputs:\n      result = output['predict']\n      print(\"The result\uff1a\",result)\n\n  mox.run(input_fn=input_fn,\n          model_fn=model_fn,\n          output_fn=output_fn,\n          run_mode=mox.ModeKeys.PREDICT,\n          batch_size=1,\n          auto_batch=False,\n          max_number_of_steps=1,\n          output_every_n_steps=1,\n          checkpoint_path=flags.train_url)\npredict()", "cell_type": "code", "execution_count": 7, "outputs": [{"output_type": "stream", "name": "stdout", "text": "INFO:tensorflow:Restoring parameters from s3://obs-dls-mnist-example/log/model.ckpt-1000\nThe result\uff1a [7]\nINFO:tensorflow:\t[1 examples]\n"}], "metadata": {}}, {"source": "\u901a\u8fc7\u9884\u6d4b\uff0c\u6211\u4eec\u80fd\u591f\u770b\u5230\u7ed3\u679c\u8f93\u51fa\u3002\n\n\n\n\u66f4\u591a\u5185\u5bb9\u8bf7\u53c2\u8003<a href =\"https://github.com/huaweicloud/dls-example/blob/master/Using%20MoXing%20to%20Create%20a%20MNIST%20Dataset%20Recognition%20Application/README.md\">\u201cMNIST_EXAMPLE\u201d</a>\u3002\n\n\n\n", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.14", "name": "python", "pygments_lexer": "ipython2", "file_extension": ".py", "codemirror_mode": {"version": 2, "name": "ipython"}}}}